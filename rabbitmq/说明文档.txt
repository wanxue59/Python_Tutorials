参考文1：RabbitMQ（pika模块）
网址：https://www.cnblogs.com/daliangtou/p/5147730.html
参考文档2：python实现RabbitMQ六种模式
网址2：https://blog.csdn.net/qq_37623764/article/details/105767004

#####################################################################################################################
参考文档：Python并发编程-RabbitMQ消息队列
网址：https://www.cnblogs.com/nulige/p/6351318.html
摘要：
二、Work Queues（一个发消息，两个收消息，收消息是公平地依次分发）
    在这种模式下，RabbitMQ会默认把p发的消息依次分发给各个消费者(c),跟负载均衡差不多。
    此时，先启动消息生产者，然后再分别启动3个消费者，通过生产者多发送几条消息，你会发现，这几条消息会被依次分配到各个
消费者身上。
    Doing a task can take a few seconds. You may wonder what happens if one of the consumers starts a long task and dies
with it only partly done. With our current code once RabbitMQ delivers message to the customer it immediately removes it
from memory. In this case, if you kill a worker we will lose the message it was just processing. We'll also lose all the
messages that were dispatched to this particular worker but were not yet handled.

    But we don't want to lose any tasks. If a worker dies, we'd like the task to be delivered to another worker.
    In order to make sure a message is never lost, RabbitMQ supports message acknowledgments. An ack(nowledgement) is
sent back from the consumer to tell RabbitMQ that a particular message had been received, processed and that RabbitMQ is
free to delete it.

    If a consumer dies (its channel is closed, connection is closed, or TCP connection is lost) without sending an ack,
RabbitMQ will understand that a message wasn't processed fully and will re-queue it. If there are other consumers online
at the same time, it will then quickly redeliver it to another consumer. That way you can be sure that no message is
lost, even if the workers occasionally die.

    There aren't any message timeouts（超时）; RabbitMQ will redeliver the message when the consumer dies. It's fine
even if processing a message takes a very, very long time.

    Message acknowledgments are turned on by default. In previous examples we explicitly（明确地） turned them off via
the auto_ack=False flag. It's time to remove this flag and send a proper acknowledgment from the worker, once we're done
with a task.

    Using this code we can be sure that even if you kill a worker using CTRL+C while it was processing a message,
nothing will be lost. Soon after the worker dies all unacknowledged messages will be redelivered.



三、消息持久化
    We have learned how to make sure that even if the consumer dies, the task isn't lost(by default（默认情况下）, if
wanna disable(禁用) use auto_ack=False). But our tasks will still be lost if RabbitMQ server stops.

    When RabbitMQ quits or crashes（崩溃；碰撞；撞车；崩盘） it will forget the queues and messages unless you tell it
not to. Two things are required to make sure that messages aren't lost: we need to mark both the queue and messages as
durable.

    First, we need to make sure that RabbitMQ will never lose our queue. In order to do so, we need to declare it as
durable:
        channel.queue_declare(queue='hello', durable=True)

    Although this command is correct by itself, it won't work in our setup. That's because we've already defined a queue
called hello which is not durable. RabbitMQ doesn't allow you to redefine an existing queue with different parameters
and will return an error to any program that tries to do that. But there is a quick workaround（变通方法） - let's
declare a queue with different name, for exampletask_queue:
        channel.queue_declare(queue='task_queue', durable=True)

    This queue_declare change needs to be applied to both the producer and consumer code.

    At that point we're sure that the task_queue queue won't be lost even if RabbitMQ restarts. Now we need to mark our
messages as persistent（持久的；顽固的） - by supplying a delivery_mode property with a value 2.



五、Publish\Subscribe（消息发布\订阅）
    之前的例子都基本都是1对1的消息发送和接收，即消息只能发送到指定的queue里，但有些时候你想让你的消息被所有的Queue收到，
类似广播的效果，这时候就要用到exchange了。

    An exchange is a very simple thing. On one side it receives messages from producers and the other side it pushes
them to queues. The exchange must know exactly what to do with a message it receives. Should it be appended to a
particular queue? Should it be appended to many queues? Or should it get discarded. The rules for that are defined by
the exchange type.

    Exchange的作用就是转发消息，给订阅者发消息。

    Exchange在定义的时候是有类型的，以决定到底是哪些Queue符合条件，可以接收消息。（一共有四种类型）
    1、fanout：所有bind到此exchange的queue都可以接收消息  （给所有人发消息）
    2、direct：通过routingKey和exchange决定的那个唯一的queue可以接收消息 （给指定的一些queue发消息）
    3、topic（话题）：所有符合routingKey(此时可以是一个表达式)的routingKey所bind的queue可以接收消息 （给订阅话题的人发消
息）
    4、headers：通过headers 来决定把消息发给哪些queue  （通过消息头，决定发送给哪些队列）

更细致的消息过滤: topic
    Although using the direct exchange improved our system, it still has limitations - it can't do routing（路由） based
on multiple（更多的） criteria（标准）.

    In our logging system we might want to subscribe to not only logs based on severity（严重程度）, but also based on
the source which emitted（发出；排放） the log. You might know this concept（概念） from the syslog unix tool, which
routes（路由） logs based on both severity(info/warn/crit...) and facility （设施）(auth/cron/kern...).

    That would give us a lot of flexibility（灵活性） - we may want to listen to just critical(重要的；关键的) errors
coming from 'cron' but also all logs from 'kern'.

topic: 意思是话题

To receive all the logs run:
    python receive_logs_topic.py "#"    # 绑定#号，就是收所有消息，相当于广播

To receive all logs from the facility "kern":
    python receive_logs_topic.py "kern.*"    # 以kern开头

Or if you want to hear only about "critical" logs:
    python receive_logs_topic.py "*.critical"    # 以critical结尾

You can create multiple bindings:
    python receive_logs_topic.py "kern.*" "*.critical"
    # 收kern开头并且以critical结尾（相当于收两个）

And to emit a log with a routing key "kern.critical" type:
    python emit_log_topic.py "kern.critical" "A critical kernel error"
    # 发消息到kern.critical里,内容是：A critical kernel error
——————————————————————————————————————————————————————————————————————————————————————————


exchange模式和非exchange模式梳理：
    简单模式是一对一，一个消费者监听一个队列。Work模式是一对多，多个消费者监听同一个队列，统称为非
exchange模式，缺点就是生产者的所有消息全堆积到同一个队列中，没有做消息分类。fanout，direct和topic统称
为exchange模式或交换机模式，该模式下的每个消费者都有自己创建的队列，采用三种方式中的任意一种来绑定交换机，
再由交换机分配消息给这些队列。exchange模式除了可以应对多个消费者之外，还可以应对消息多样化，因为MQ不知道
这个消息到底分给哪个消费者来做，比如一个项目里面，有发送邮件，有发送支付短信，有赠送优惠券，这就是三类消息，
使用exchange模式就很好应对，生产者和消费者两端商量好，双方都用send_email作为关键字，来表明这个是发邮件的
消息，那交换机就会按照send_email去找队列，就完成了该队列只用于存放邮箱地址。其他类的消息双方又商量同时用
另外一个关键字。应用场景最多的就是发布订阅和关键字模式。

    RPC——远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议，
和RabbitMQ没有必然关系，RPC可以基于tcp或http，http是基于tcp的，RPC直接工作在会话层。在OSI网络通信模型
中，RPC跨越了传输层和应用层。RPC使分布式系统中的应用程序通信更加容易，RPC采用C/S模式。

    在MQ的RPC模式中：客户端和服务器两边都在生产消息也在监听队列，客户端启动时，它将创建一个回调队列(可以
是个随机队列，就是上图下方的reply_to那个队列)，对于RPC请求，客户端发送一条消息，该消息中要带上两个属性：
reply_to(回调队列，告诉服务器端你把结果给我放进我的创建的这个回调队列)和correlation_id(请求的唯一标识)，
塞进rpc_queue队列。服务器端正在监听。出现消息后，服务器端处理消息再把响应数据以及correlation_id按照
reply_to字段中的指向，塞进那个回调队列。客户端监听这个回调队列，回调队列出现消息后，客户端将检查
correlation_id与它请求时带的值是否一致，一致的话说明正是客户端这次RPC请求的响应结果。这儿RPC模式它怪就怪
在这儿，发起RPC请求的一方能通过跟服务器商量，让服务器按要求把响应数据返回回来。RPC基本会用在公司内部系统上
下游的应用程序通信，因为传输文件不能过大，所以对外基本是使用http的restful接口。用RabbitMQ来实现RPC模式，
下面案例的目标就是客户端想用RPC请求调用另一台机上的fun函数，并且还要拿到响应结果。


